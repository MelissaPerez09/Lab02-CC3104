{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b08a879",
   "metadata": {},
   "source": [
    "## Laboratorio 02 - MDP\n",
    "Integrantes:\n",
    "- Ricardo Méndez\n",
    "- Sara Echevería\n",
    "- Melissa Pérez\n",
    "\n",
    "Repositorio: https://github.com/MelissaPerez09/Lab02-CC3104"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0847a12",
   "metadata": {},
   "source": [
    "### Task 01\n",
    "1. ¿Qué es un Markov Decision Process (MDP)?\n",
    "    - Es un modelo matemático donde un agente interactúa con el entorno, principalmente busca maximizar una recompensa acumulada. Se basa en la propiedad de Markov por lo que la toma de decisiones se basa en el estado actual y no en los estados pasados.\n",
    "2. ¿Cuáles son los componentes principales de un MDP?\n",
    "    - `S`: conjunto de estados posibles del entorno.\n",
    "    - `A`: conjunto de acciones que el agente puede tomar.\n",
    "    - `P(s'|s, a)`: función de transición de probabilidad, que describe la probabilidad de pasar al estado `s'` al tomar la acción a desde el estado `s`.\n",
    "    - `R(s, a)`: función de recompensa, que asigna un valor numérico (recompensa esperada) al tomar la acción a en el estado `s`.\n",
    "    - `γ (gamma)`: factor de descuento, un valor entre 0 y 1 que determina la importancia de las recompensas futuras frente a las inmediatas.\n",
    "3. ¿Cuál es el objetivo principal del aprendizaje por refuerzo con MDPs?\n",
    "    - Aprender una política óptima, que define qué acción tomar en cada estado para maximizar la recompensa acumulada a largo plazo. Esto se logra evaluando y mejorando políticas mediante métodos como Value Iteration, Policy Iteration, o algoritmos como Q-learning o SARSA.\n",
    "\n",
    "_Givan, Bob. An Introduction to Markov Decision Processes https://www.cs.rice.edu/~vardi/dag01/givan1.pdf_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcfb130",
   "metadata": {},
   "source": [
    "### Task 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e706a7f6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "641568a6",
   "metadata": {},
   "source": [
    "### Task 03"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
